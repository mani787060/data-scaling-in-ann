# Data Scaling in Artificial Neural Networks (ANN)

This project demonstrates the importance of **data scaling** while training Artificial Neural Networks and visualizes the effect of scaling using scatter plots.

---

## Objective
To understand why data scaling is critical for ANN training and how it affects:
- Weight updates
- Gradient descent convergence
- Model stability

---

## What This Notebook Covers
- Why data scaling is required in neural networks
- Common scaling techniques:
  - Standardization
  - Min-Max Scaling
- Visualization of data before and after scaling using scatter plots
- Impact of scaling on ANN training behavior

---

## Key Learnings
- Unscaled features can dominate gradient updates and slow down learning.
- Proper scaling leads to faster convergence and more stable training.
- Scatter plots help visualize how scaling transforms feature distributions.

---

## Tech Stack
- Python
- NumPy
- Pandas
- Matplotlib / Seaborn
- Scikit-learn

---

## Project Purpose
This project builds a strong foundation for training deep learning models by highlighting the role of data preprocessing in Artificial Neural Networks.


